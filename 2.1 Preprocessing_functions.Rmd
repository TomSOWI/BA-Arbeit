---
title: "Preprocessing"
author: "Tom Klotz"
date: "3 5 2023"
output: html_document
---



## Test Case foor creating functions
### Cleaning and keeping docvars
```{r}
corp_test <- corpus(testing$speech_content, 
                      docvars = data.frame(docname = testing$id, party = testing$party))

toks <- tokens(corp_test, remove_punct = T, remove_symbols = T, remove_numbers = T)
toks <- tokens_tolower(toks)
toks <- tokens_remove(toks, stopwords("german"))

corp_test <- vapply(toks, paste, FUN.VALUE = character(1), collapse = " ") %>%corpus()

df <- cbind(corp_test, docvars(toks))
rownames(df) <- df$docname

corp_test <- corpus(df, text_field = "corp_test") 

```


```{r}
#Dictionary context
terms <- popdictR::gruendl_terms
dict <- dictionary(list(populismus = terms))
is.dictionary(dict) #true


df_kwic <- kwic(corp_test, pattern = dict$populismus, valuetype = "regex", window = 5)



#combine pre and after
df_kwic$context <- paste(df_kwic$pre, df_kwic$post, sep = " ")
df_kwic <- as.data.frame(df_kwic) %>% select(docname,pattern,context)


df$corp_test <- NULL
class(df_kwic$docname) == class(df$docname) #false
df$docname  <- as.character(df$docname)
class(df_kwic$docname) == class(df$docname) #true

df_test <- merge(df_kwic, df) #add party column




```


### Distance measure
```{r}
toks <- tokens(df_test$context)

dfm_test <- quanteda::dfm(toks)
dtm.matrix <- as.matrix(dfm_test) 


dist_test = proxy::dist(dtm.matrix, method = "euclidean")



```

### K-Means
```{r}
set.seed(123)
truth.K = 2  # wie viele dimensionen?

clustering.kmeans <- kmeans(dist_test, truth.K, iter.max = 10, nstart = 2)

print(clustering.kmeans)

class(dist.matrix)

fviz_nbclust(dtm.matrix, kmeans, method = "wss") +    # total intra-cluster variation
  geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method")
```


```{r}
df_complete$cluster <- clustering.kmeans$cluster
###Anteil AfD und Linke


  
df_afd <- df_complete[df_complete$party == "AfD",] 

prop.table(table(df_afd$cluster))

df_linke <- df_complete[df_complete$party == "DIE LINKE.",] 

prop.table(table(df_linke$cluster))

#1 is populism
#2 is not populism

df_complete$cluster[df_complete$cluster == 2] <- 0
```


```{r}


df_aggre <- aggregate(df_complete$cluster, by = list(df_complete$pattern), FUN = "mean")



```


### Functions
```{r, echo=FALSE}
#Cleaning
corpus_cleaning <- function(dataframe){
  corp <- corpus(dataframe$speech_content, docvars = data.frame(docname = dataframe$id, party = dataframe$party))
  toks <- tokens(corp, remove_punct = T, remove_symbols = T, remove_numbers = T, include_docvars = T)
  toks <- tokens_tolower(toks)
  toks <- tokens_remove(toks, stopwords("german"))
  corp <- vapply(toks, paste, FUN.VALUE = character(1), collapse = " ") %>%
  corpus()
  df <- cbind(corp, docvars(toks)) 
  rownames(df) <- df$docname
  assign("docvars", df,  envir = globalenv()) # für corpus_to_poppulism_context_df
  corp <- corpus(docvars, text_field = "corp")
}

#Dictionary context
### Main terms
terms <- popdictR::gruendl_terms
dict <- dictionary(list(populismus = terms))


### Total considered terms

t <- popdictR::gruendl_dictionary_complete
terms_total <- popdictR::gruendl_dictionary_complete %>% select(Word,Sub_Type,Comment,duplicate, real_duplicate,wildcard)

terms_total$filter <- ifelse(terms_total$Word %in% terms, 1,0)
table(terms_total$filter)

terms_df <- terms_total[terms_total$filter ==1,]

terms_fixed <- terms_df[terms_df$wildcard != "regex" & !(terms_df$Word %in% c("hausverstand(s|es)?",	
"staatsversagen(s)?","täusch(t|en)")),]
terms_regex <- terms_df[terms_df$wildcard == "regex"| terms_df$Word %in% c("hausverstand(s|es)?",	
"staatsversagen(s)?","täusch(t|en)"),]

dict_fixed <- dictionary(list(populismus = terms_fixed$Word))
dict_regex <- dictionary(list(populismus = terms_regex$Word))




terms_exp <- terms_total %>% filter(grepl('old term', Comment)) #1
terms_exp <- na.omit(terms_total[terms_total$Comment == "appears too often? (>2000)",]) #1
terms_exp <- terms_total %>% filter(grepl('included', Comment)) #0
terms_exp <- terms_total %>% filter(grepl('is better', Comment)) #1
terms_exp <- terms_total %>% filter(grepl('captures something different', Comment)) #1
terms_exp <- na.omit(terms_total[terms_total$Comment == "check",])#0
terms_exp <- na.omit(terms_total[terms_total$Comment == "too much abgasmanipulation",])#1
terms_exp <- na.omit(terms_total[terms_total$Comment == "rechts?",])#1
terms_exp <- terms_total %>% filter(grepl('not useful', Comment)) #1

  
terms_total <- terms_total %>% filter(!grepl(c("old term|appears too often? (>2000)|is better|captures something different|too much abgasmanipulation|rechts?|not useful"), Comment)) #1

terms_total_duplicate <- terms_total[terms_total$duplicate == TRUE,] #no issue
dict_total <- dictionary(list(populismus = terms_total$Word))


corpus_to_poppulism_context_df <- function(corp){
  df_kwic <- kwic(corp, pattern = dict$populismus, valuetype = "regex", window = 5) #window 
  #combine pre and after
  df_kwic$context <- paste(df_kwic$pre, df_kwic$post, sep = " ")
  df_kwic <- as.data.frame(df_kwic) %>% select(docname,pattern,context)
  docvars$corp <- NULL #aus corpus cleaning
  docvars$docname  <- as.character(docvars$docname)
  df_complete <- merge(df_kwic, docvars) #add party colum
}

corpus_to_poppulism_context_df_total <- function(corp){
  df_kwic <- kwic(corp, pattern = dict_total$populismus, valuetype = "regex", window = 5) #window 
  #combine pre and after
  df_kwic$context <- paste(df_kwic$pre, df_kwic$post, sep = " ")
  df_kwic <- as.data.frame(df_kwic) %>% select(docname,pattern,context)
  docvars$corp <- NULL #aus corpus cleaning
  docvars$docname  <- as.character(docvars$docname)
  df_complete <- merge(df_kwic, docvars) #add party colum
}

#For Lemmetazation
#ud_model <- udpipe_download_model("german")

#tokens_lemm <- function(toks){
#  char <- as.character(toks)
#  stem <- udpipe_annotate(ud_model, char)
#  df <- as.data.frame(stem)
#  toks <- tokens(df$lemma)
#}


distance.matrix <- function(df){
  toks <- tokens(df$context)
  dfm <- dfm(toks) 
  dtm.matrix <- as.matrix(dfm)
  dist.matrix <-proxyC::dist(dtm.matrix, method = "euclidean")
}




#ud_model <- udpipe_load_model(ud_model)

#tokens_lemm <- function(toks){
#  char <- as.character(toks)
#stem <- udpipe_annotate(ud_model, char)
#  df <- as.data.frame(stem)
  #toks <- tokens(df$lemma)
#}


```

### Verifying that functions produce the same output

```{r}
corp_verify <- corpus_cleaning(testing)
corp_verify == corp_test #check

df_verify <- corpus_to_poppulism_context_df(corp_verify)
df_verify == df_test #check

dist_verify <- distance.matrix(df_verify)
dist_verify == dist_test #check

print(dist_verify)


```

```{r}
#Lemmitazation
#download german ud model
#ud_model <- udpipe_download_model("german")
#ud_model <- udpipe_load_model(ud_model)

#tokens_lemm <- function(toks){
#  char <- as.character(toks)
#stem <- udpipe_annotate(ud_model, char)
#  df <- as.data.frame(stem)
  #toks <- tokens(df$lemma)
#}
```



